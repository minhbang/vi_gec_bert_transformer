{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TRAIN2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYSm8fhI4xYuI+KZsM9PHD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ujBAIzdOJGE7","colab_type":"text"},"source":["# Bật GPU\n","\"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\""]},{"cell_type":"code","metadata":{"id":"eGTO0iTkmo3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1595887476966,"user_tz":-420,"elapsed":8152,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"7499af55-9772-453b-9cb6-4bad1c016b85"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mon Jul 27 22:04:32 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kTs3cLhuljBE","colab_type":"text"},"source":["# Cài đặt các gói cần thiết"]},{"cell_type":"code","metadata":{"id":"yIJuTMpslm4z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595887524939,"user_tz":-420,"elapsed":56117,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"951cfab1-abad-40d7-943b-da20cbb16134"},"source":["!pip3 install fairseq\n","!pip3 install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n","\r\u001b[K     |█                               | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/5b/cf661da8e9b0229f5d98c2961b072a5728fd11a0758957f8c0fd36081c06/sacrebleu-1.4.12-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.1+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/3b/e7/ceef002a300a98a208232fab593183249b6964b306ee7dabb29908419cca/portalocker-1.7.1-py2.py3-none-any.whl\n","Collecting mecab-python3==0.996.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n","\u001b[K     |████████████████████████████████| 17.1MB 202kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2021632 sha256=de01ea977981ea3d98d870b580cdc33d77a12bbca96ec16f27ed9b3dc72daab7\n","  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n","Successfully built fairseq\n","Installing collected packages: portalocker, mecab-python3, sacrebleu, fairseq\n","Successfully installed fairseq-0.9.0 mecab-python3-0.996.5 portalocker-1.7.1 sacrebleu-1.4.12\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 4.4MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 19.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 30.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 48.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=e69fdf5ae23aab7909b453807a3bb8685dc49da0c6d4a6ef5777d1b787eb2740\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9O-3hMyzJkf3","colab_type":"text"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"PdFutqNzI8gu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"ok","timestamp":1595887561393,"user_tz":-420,"elapsed":92562,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"931e99e8-451f-467e-908d-9025345b55f2"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","root_dir = \"/content/drive/My\\ Drive/MasterThesis/CoLab/code_final\"\n","src_dir = \"%s/src\" % root_dir\n","!ls $root_dir\n","!ls $src_dir\n","import sys\n","sys.path.append(src_dir)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","cache\tdata\t      src\t TRAIN1.sh    TRAIN2.ipynb\n","corpus\tmodel_stage1  TRAIN0.sh  TRAIN2.bash  TRAIN3.bash\n","bert_tokenize.py\t __init__.py\tsave_vocab_file.py\n","dictionary_with_bert.py  preprocess.py\ttransformer_with_pretrained_bert.py\n","gec_data_split.py\t __pycache__\ttranslation_with_bert.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5m7SGU8Bn5Ir","colab_type":"text"},"source":["# Stage 1: Decoder training"]},{"cell_type":"code","metadata":{"id":"Gr3oE2nSpB2T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595887563869,"user_tz":-420,"elapsed":95030,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}}},"source":["SRC='input'\n","TRG='target'\n","BERT_MODEL='bert-base-multilingual-cased'\n","UPDATES_PER_EPOCH=9000\n","DISP_FREQ=int(UPDATES_PER_EPOCH / 5)\n","TOKENS_PER_GPU=10000\n","UPDATE_FREQ=4\n","TRAIN_EPOCHS=20\n","LR=0.0004\n","DROPOUT=0.15\n","WARMUP_EPOCHS=5\n","WARMUP=UPDATES_PER_EPOCH * WARMUP_EPOCHS\n","\n","DATA=\"%s/data\" % root_dir\n","CODE=src_dir\n","MODEL_OUT=\"%s/model_stage1\" % root_dir\n","!mkdir -p $MODEL_OUT"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"oebNUIo1n-We","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595909976050,"user_tz":-420,"elapsed":14238451,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"166814d8-82cc-4abc-d3b9-ed7ae3146804"},"source":["!fairseq-train \"/content/drive/My Drive/MasterThesis/CoLab/code_final/data\" -s $SRC -t $TRG \\\n","  --ddp-backend no_c10d \\\n","  --user-dir \"/content/drive/My Drive/MasterThesis/CoLab/code_final/src\" \\\n","  --task translation_with_bert \\\n","  --bert-model $BERT_MODEL \\\n","  --arch transformer_with_pretrained_bert \\\n","  --log-format simple \\\n","  --log-interval $DISP_FREQ \\\n","  --max-tokens $TOKENS_PER_GPU \\\n","  --update-freq $UPDATE_FREQ \\\n","  --max-epoch $TRAIN_EPOCHS \\\n","  --optimizer adam \\\n","  --lr $LR \\\n","  --adam-betas '(0.9, 0.99)' \\\n","  --label-smoothing 0.1 \\\n","  --clip-norm 5 \\\n","  --dropout $DROPOUT \\\n","  --min-lr '1e-09' \\\n","  --lr-scheduler inverse_sqrt \\\n","  --weight-decay 0.0001 \\\n","  --criterion label_smoothed_cross_entropy \\\n","  --warmup-updates $WARMUP \\\n","  --warmup-init-lr '1e-07' \\\n","  --reset-optimizer \\\n","  --fp16 \\\n","  --save-dir \"/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage1\" \\\n","  2>&1 | tee \"/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage1/training.log\"\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["2020-07-28 00:22:20.365334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.99)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_with_pretrained_bert', attention_dropout=0.0, bert_model='bert-base-multilingual-cased', best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=5.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/drive/My Drive/MasterThesis/CoLab/code_final/data', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.15, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fine_tuning=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source=False, left_pad_target='False', load_alignments=False, log_format='simple', log_interval=1800, lr=[0.0004], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=10000, max_tokens_valid=10000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='checkpoint_last.pt', save_dir='/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage1', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='input', target_lang='target', task='translation_with_bert', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[4], upsample_primary=1, use_bmuf=False, user_dir='/content/drive/My Drive/MasterThesis/CoLab/code_final/src', valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=45000, weight_decay=0.0001)\n","| [input] dictionary: 119547 types\n","| [target] dictionary: 16184 types\n","| loaded 552286 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/valid.input-target.input\n","| loaded 552286 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/valid.input-target.target\n","| /content/drive/My Drive/MasterThesis/CoLab/code_final/data valid input-target 552286 examples\n","TransformerWithBertModel(\n","  (encoder): TransformerWithBertEncoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoder(\n","    (embed_tokens): Embedding(16184, 768, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","| model transformer_with_pretrained_bert, criterion LabelSmoothedCrossEntropyCriterion\n","| num. model params: 259422720 (num. trained: 259422720)\n","| training on 1 GPUs\n","| max tokens per GPU = 10000 and max sentences per GPU = None\n","| loaded checkpoint /content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage1/checkpoint_last.pt (epoch 17 @ 0 updates)\n","| loading train data for epoch 17\n","| loaded 2209144 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/train.input-target.input\n","| loaded 2209144 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/train.input-target.target\n","| /content/drive/My Drive/MasterThesis/CoLab/code_final/data train input-target 2209144 examples\n","| WARNING: overflow detected, setting loss scale to: 64.0\n","| WARNING: overflow detected, setting loss scale to: 32.0\n","| epoch 018:   1800 / 1816 loss=1.903, nll_loss=0.171, ppl=1.13, wps=15559, ups=0, wpb=33622.526, bsz=1216.907, num_updates=1799, lr=1.60871e-05, gnorm=0.072, clip=0.000, oom=0.000, loss_scale=32.000, wall=3908, train_wall=78334\n","| epoch 018 | loss 1.903 | nll_loss 0.170 | ppl 1.13 | wps 15559 | ups 0 | wpb 33614.894 | bsz 1216.864 | num_updates 1814 | lr 1.62204e-05 | gnorm 0.072 | clip 0.000 | oom 0.000 | loss_scale 32.000 | wall 3939 | train_wall 78365\n","/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n","| epoch 018 | valid on 'valid' subset | loss 2.251 | nll_loss 0.554 | ppl 1.47 | num_updates 1814\n","| saved checkpoint /content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage1/checkpoint18.pt (epoch 18 @ 1814 updates) (writing took 239.44779586791992 seconds)\n","| epoch 019:   1800 / 1816 loss=1.895, nll_loss=0.164, ppl=1.12, wps=15356, ups=0, wpb=33626.069, bsz=1217.341, num_updates=3615, lr=3.22253e-05, gnorm=0.043, clip=0.000, oom=0.000, loss_scale=32.000, wall=8699, train_wall=82169\n","| epoch 019 | loss 1.895 | nll_loss 0.164 | ppl 1.12 | wps 15355 | ups 0 | wpb 33615.312 | bsz 1216.489 | num_updates 3630 | lr 3.23586e-05 | gnorm 0.043 | clip 0.000 | oom 0.000 | loss_scale 32.000 | wall 8731 | train_wall 82200\n","| epoch 019 | valid on 'valid' subset | loss 2.254 | nll_loss 0.561 | ppl 1.48 | num_updates 3630 | best_loss 2.25085\n","| saved checkpoint /content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage1/checkpoint19.pt (epoch 19 @ 3630 updates) (writing took 113.37447667121887 seconds)\n","| epoch 020:   1800 / 1816 loss=1.892, nll_loss=0.162, ppl=1.12, wps=15268, ups=0, wpb=33626.399, bsz=1216.728, num_updates=5431, lr=4.83635e-05, gnorm=0.039, clip=0.000, oom=0.000, loss_scale=64.000, wall=13391, train_wall=86029\n","| epoch 020 | loss 1.892 | nll_loss 0.162 | ppl 1.12 | wps 15266 | ups 0 | wpb 33615.312 | bsz 1216.489 | num_updates 5446 | lr 4.84968e-05 | gnorm 0.039 | clip 0.000 | oom 0.000 | loss_scale 64.000 | wall 13423 | train_wall 86060\n","| epoch 020 | valid on 'valid' subset | loss 2.256 | nll_loss 0.567 | ppl 1.48 | num_updates 5446 | best_loss 2.25085\n","| saved checkpoint /content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage1/checkpoint20.pt (epoch 20 @ 5446 updates) (writing took 113.39689469337463 seconds)\n","| done training in 14100.3 seconds\n"],"name":"stdout"}]}]}