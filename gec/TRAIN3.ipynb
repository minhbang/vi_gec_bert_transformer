{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TRAIN3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOHyNSa5uWXHyHvArzpJeVu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ujBAIzdOJGE7","colab_type":"text"},"source":["# Bật GPU\n","\"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\""]},{"cell_type":"code","metadata":{"id":"eGTO0iTkmo3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1596368156894,"user_tz":-420,"elapsed":2880,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"ece2aafb-e7c9-4dea-abdb-c7bdfabaa809"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sun Aug  2 11:35:55 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kTs3cLhuljBE","colab_type":"text"},"source":["# Cài đặt các gói cần thiết"]},{"cell_type":"code","metadata":{"id":"yIJuTMpslm4z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596368200488,"user_tz":-420,"elapsed":46461,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"5ec438a1-64a0-4d46-d246-0af6b8b23a72"},"source":["!pip3 install fairseq\n","!pip3 install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n","\u001b[K     |████████████████████████████████| 307kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/d3/be980ad7cda7c4bbfa97ee3de062fb3014fc1a34d6dd5b82d7b92f8d6522/sacrebleu-1.4.13-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.6.0+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2046375 sha256=336b5f693fa92db4cf7fc4d72ea1747889d15cc71a671bbc2501c1b87adfe7bc\n","  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n","Successfully built fairseq\n","Installing collected packages: portalocker, sacrebleu, fairseq\n","Successfully installed fairseq-0.9.0 portalocker-2.0.0 sacrebleu-1.4.13\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 23.6MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 38.5MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 64.1MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=e31b77c25730af8e42e8b6ebc0356be28450b086dfe1a1d56b00502146936869\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9O-3hMyzJkf3","colab_type":"text"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"PdFutqNzI8gu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"ok","timestamp":1596368225565,"user_tz":-420,"elapsed":71530,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"be563a33-be4e-4be4-9fac-936ef5ee8c53"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","root_dir = \"/content/drive/My\\ Drive/MasterThesis/CoLab/code_final\"\n","src_dir = \"%s/src\" % root_dir\n","!ls $root_dir\n","!ls $src_dir\n","import sys\n","sys.path.append(src_dir)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","cache\tdata\t      model_stage2  src\t\tTRAIN0.sh  TRAIN2.ipynb\n","corpus\tmodel_stage1  output\t    TEST.ipynb\tTRAIN1.sh  TRAIN3.ipynb\n","bert_tokenize.py\t __init__.py\tsave_vocab_file.py\n","dictionary_with_bert.py  preprocess.py\ttransformer_with_pretrained_bert.py\n","gec_data_split.py\t __pycache__\ttranslation_with_bert.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5m7SGU8Bn5Ir","colab_type":"text"},"source":["# Stage 2: Fine-tuning"]},{"cell_type":"code","metadata":{"id":"Gr3oE2nSpB2T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596368227631,"user_tz":-420,"elapsed":73593,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}}},"source":["SRC='input'\n","TRG='target'\n","BERT_MODEL='bert-base-multilingual-cased'\n","UPDATES_PER_EPOCH=9000\n","DISP_FREQ=int(UPDATES_PER_EPOCH / 5)\n","TOKENS_PER_GPU=5000\n","UPDATE_FREQ=4\n","TRAIN_EPOCHS=50\n","LR=0.00008\n","DROPOUT=0.15\n","WARMUP_EPOCHS=1\n","WARMUP=UPDATES_PER_EPOCH * WARMUP_EPOCHS\n","\n","DATA=\"%s/data\" % root_dir\n","CODE=src_dir\n","MODEL_IN=\"%s/model_stage1\" % root_dir\n","MODEL_OUT=\"%s/model_stage2\" % root_dir\n","!mkdir -p $MODEL_OUT\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3OK-kGHQKLX","colab_type":"text"},"source":["--restore-file $MODEL_IN/checkpoint_best.pt \\"]},{"cell_type":"code","metadata":{"id":"oebNUIo1n-We","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596391420821,"user_tz":-420,"elapsed":23266775,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"3c0c3af0-d6a5-4933-80ce-fe06eee21f92"},"source":["!fairseq-train \"/content/drive/My Drive/MasterThesis/CoLab/code_final/data\" -s $SRC -t $TRG \\\n","  --ddp-backend no_c10d \\\n","  --user-dir \"/content/drive/My Drive/MasterThesis/CoLab/code_final/src\" \\\n","  --task translation_with_bert \\\n","  --bert-model $BERT_MODEL \\\n","  --arch transformer_with_pretrained_bert \\\n","  --fine-tuning \\\n","  --log-format simple \\\n","  --log-interval $DISP_FREQ \\\n","  --max-tokens $TOKENS_PER_GPU \\\n","  --update-freq $UPDATE_FREQ \\\n","  --max-epoch $TRAIN_EPOCHS \\\n","  --optimizer adam \\\n","  --lr $LR \\\n","  --adam-betas '(0.9, 0.99)' \\\n","  --label-smoothing 0.1 \\\n","  --clip-norm 5 \\\n","  --dropout $DROPOUT \\\n","  --min-lr '1e-09' \\\n","  --lr-scheduler inverse_sqrt \\\n","  --weight-decay 0.0001 \\\n","  --criterion label_smoothed_cross_entropy \\\n","  --warmup-updates $WARMUP \\\n","  --warmup-init-lr '1e-07' \\\n","  --reset-lr-scheduler --reset-meters --reset-optimizer \\\n","  --save-interval 1 \\\n","  --keep-last-epochs 2 \\\n","  --save-dir \"/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage2\" \\\n","  2>&1 | tee \"/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage2/training.log\"\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2020-08-02 11:37:09.912416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100%|██████████| 625/625 [00:00<00:00, 581kB/s]\n","Downloading: 100%|██████████| 714M/714M [00:07<00:00, 95.6MB/s]Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.99)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_with_pretrained_bert', attention_dropout=0.0, bert_model='bert-base-multilingual-cased', best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=5.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/drive/My Drive/MasterThesis/CoLab/code_final/data', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.15, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fine_tuning=True, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=2, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source=False, left_pad_target='False', load_alignments=False, log_format='simple', log_interval=1800, lr=[8e-05], lr_scheduler='inverse_sqrt', max_epoch=50, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=5000, max_tokens_valid=5000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='checkpoint_last.pt', save_dir='/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage2', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='input', target_lang='target', task='translation_with_bert', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[4], upsample_primary=1, use_bmuf=False, user_dir='/content/drive/My Drive/MasterThesis/CoLab/code_final/src', valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=9000, weight_decay=0.0001)\n","| [input] dictionary: 119547 types\n","| [target] dictionary: 16184 types\n","| loaded 552286 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/valid.input-target.input\n","| loaded 552286 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/valid.input-target.target\n","| /content/drive/My Drive/MasterThesis/CoLab/code_final/data valid input-target 552286 examples\n","TransformerWithBertModel(\n","  (encoder): TransformerWithBertEncoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoder(\n","    (embed_tokens): Embedding(16184, 768, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","| model transformer_with_pretrained_bert, criterion LabelSmoothedCrossEntropyCriterion\n","| num. model params: 259422720 (num. trained: 259422720)\n","| training on 1 GPUs\n","| max tokens per GPU = 5000 and max sentences per GPU = None\n","| loaded checkpoint /content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage2/checkpoint_last.pt (epoch 44 @ 0 updates)\n","| loading train data for epoch 44\n","| loaded 2209144 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/train.input-target.input\n","| loaded 2209144 examples from: /content/drive/My Drive/MasterThesis/CoLab/code_final/data/train.input-target.target\n","| /content/drive/My Drive/MasterThesis/CoLab/code_final/data train input-target 2209144 examples\n","\n","| epoch 045:   1800 / 3684 loss=1.877, nll_loss=0.157, ppl=1.12, wps=5559, ups=0, wpb=16551.803, bsz=600.937, num_updates=1801, lr=1.60889e-05, gnorm=0.057, clip=0.000, oom=0.000, wall=5419, train_wall=5295\n","| epoch 045:   3600 / 3684 loss=1.876, nll_loss=0.157, ppl=1.12, wps=5564, ups=0, wpb=16566.267, bsz=599.569, num_updates=3601, lr=3.20689e-05, gnorm=0.054, clip=0.000, oom=0.000, wall=10779, train_wall=10588\n","| epoch 045 | loss 1.876 | nll_loss 0.157 | ppl 1.12 | wps 5564 | ups 0 | wpb 16570.414 | bsz 599.659 | num_updates 3684 | lr 3.28057e-05 | gnorm 0.054 | clip 0.000 | oom 0.000 | wall 11028 | train_wall 10834\n","/usr/local/lib/python3.6/dist-packages/fairseq/optim/adam.py:160: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n","  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","| epoch 045 | valid on 'valid' subset | loss 2.181 | nll_loss 0.484 | ppl 1.4 | num_updates 3684\n","| saved checkpoint /content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage2/checkpoint45.pt (epoch 45 @ 3684 updates) (writing took 173.79528737068176 seconds)\n","| epoch 046:   1800 / 3684 loss=1.876, nll_loss=0.157, ppl=1.12, wps=5553, ups=0, wpb=16567.862, bsz=601.590, num_updates=5485, lr=4.87946e-05, gnorm=0.058, clip=0.000, oom=0.000, wall=17550, train_wall=16133\n","tee: '/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage2/training.log': Transport endpoint is not connected\n","| epoch 046:   3600 / 3684 loss=1.877, nll_loss=0.157, ppl=1.12, wps=5562, ups=0, wpb=16571.745, bsz=600.287, num_updates=7285, lr=6.47746e-05, gnorm=0.062, clip=0.000, oom=0.000, wall=22905, train_wall=21422\n","| epoch 046 | loss 1.877 | nll_loss 0.158 | ppl 1.12 | wps 5563 | ups 0 | wpb 16570.414 | bsz 599.659 | num_updates 7368 | lr 6.55115e-05 | gnorm 0.063 | clip 0.000 | oom 0.000 | wall 23151 | train_wall 21664\n","ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n","\u0000Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 779, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n","    if not self._poll(timeout):\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n","    return self._poll(timeout)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n","    r = wait([self], timeout)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n","    fd_event_list = self._poll.poll(timeout)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n","    _error_if_any_worker_fails()\n","RuntimeError: DataLoader worker (pid 7916) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\n","    sys.exit(cli_main())\n","  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 333, in cli_main\n","    main(args)\n","  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 89, in main\n","    valid_losses = validate(args, trainer, task, epoch_itr, valid_subsets)\n","  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 239, in validate\n","    for sample in progress:\n","  File \"/usr/local/lib/python3.6/dist-packages/fairseq/progress_bar.py\", line 181, in __iter__\n","    for i, obj in enumerate(self.iterable, start=self.offset):\n","  File \"/usr/local/lib/python3.6/dist-packages/fairseq/data/iterators.py\", line 36, in __iter__\n","    for x in self.iterable:\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 974, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 792, in _try_get_data\n","    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))\n","RuntimeError: DataLoader worker (pid(s) 7916) exited unexpectedly\n"],"name":"stdout"}]}]}