{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TRANSLATE.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMEMGNjbHa49Wrh9PomWZXD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"105711adf056495182666586fea45cef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a31b05561e1c429c9b9e46ee6ff0d9f7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_461683a1fab74a20975eb48a24a67c08","IPY_MODEL_560f0aaeab2a47129260b0c3dd724611"]}},"a31b05561e1c429c9b9e46ee6ff0d9f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"461683a1fab74a20975eb48a24a67c08":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b80dbc185f0742b98a95ceaee8c27462","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81972fce9a7543b1a6982b37f3635095"}},"560f0aaeab2a47129260b0c3dd724611":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_272c966cea0345d18f73bf1ef8066f8d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:01&lt;00:00, 815kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89666e72b0224f79a1b6a91b801c4e12"}},"b80dbc185f0742b98a95ceaee8c27462":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"81972fce9a7543b1a6982b37f3635095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"272c966cea0345d18f73bf1ef8066f8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89666e72b0224f79a1b6a91b801c4e12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd40778eabb64c368f1a501267b11e32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_719ffb0474d043ceba33af317f6494fd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_629ea809b4f1440184c113905e01a1bc","IPY_MODEL_c70f014d37a6457e84343c998032caa3"]}},"719ffb0474d043ceba33af317f6494fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"629ea809b4f1440184c113905e01a1bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a5d21435a9334d0cb34cd8a644066590","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7420e76e086047be838614cc9704200b"}},"c70f014d37a6457e84343c998032caa3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_026152914048486ba71246516fb57a21","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [03:43&lt;00:00, 2.79B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05481e14183f433dbc0c6af660f2eeec"}},"a5d21435a9334d0cb34cd8a644066590":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7420e76e086047be838614cc9704200b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"026152914048486ba71246516fb57a21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"05481e14183f433dbc0c6af660f2eeec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b781a434a8d440d2a50b5ae2aef0ec8c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a3fc4dbc1b542ec969c845ffb665eef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5cc0e740766845c29c4a511d5731dab3","IPY_MODEL_e22254df7aa44477a18499019313b1e0"]}},"0a3fc4dbc1b542ec969c845ffb665eef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cc0e740766845c29c4a511d5731dab3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3a633af6a69a4e88a47189fb880b2b3b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_27d636bc27174495921a5c714ef2c91d"}},"e22254df7aa44477a18499019313b1e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83e9b2db975b4aaa8a601644aa8b30fe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:16&lt;00:00, 43.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a638fdf441dd426f90a219963a057018"}},"3a633af6a69a4e88a47189fb880b2b3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"27d636bc27174495921a5c714ef2c91d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83e9b2db975b4aaa8a601644aa8b30fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a638fdf441dd426f90a219963a057018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"ujBAIzdOJGE7","colab_type":"text"},"source":["# Bật GPU\n","\"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\""]},{"cell_type":"code","metadata":{"id":"eGTO0iTkmo3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1597131498385,"user_tz":-420,"elapsed":7510,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"369d74c9-04c0-4ef6-b52d-1cf5139fd32a"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 11 07:38:14 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kTs3cLhuljBE","colab_type":"text"},"source":["# Cài đặt các gói cần thiết"]},{"cell_type":"code","metadata":{"id":"yIJuTMpslm4z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597131571359,"user_tz":-420,"elapsed":80472,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"95058990-6ba1-4000-ce7e-a22ca4dea2b3"},"source":["%%shell\n","pip3 install transformers\n","git clone https://github.com/pytorch/fairseq\n","cd fairseq\n","pip3 install ./"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\r\u001b[K     |▍                               | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 1.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.1MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 2.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 6.7MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 13.1MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 19.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=a9fc550498b176fd40ab929a752a8f97d3cc7b0cf1fb03c3fd515da9b9195fcc\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n","Cloning into 'fairseq'...\n","remote: Enumerating objects: 61, done.\u001b[K\n","remote: Counting objects: 100% (61/61), done.\u001b[K\n","remote: Compressing objects: 100% (47/47), done.\u001b[K\n","remote: Total 17147 (delta 26), reused 34 (delta 14), pack-reused 17086\u001b[K\n","Receiving objects: 100% (17147/17147), 7.93 MiB | 6.11 MiB/s, done.\n","Resolving deltas: 100% (12630/12630), done.\n","Processing /content/fairseq\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.6.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (4.41.1)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.14.1)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/d3/be980ad7cda7c4bbfa97ee3de062fb3014fc1a34d6dd5b82d7b92f8d6522/sacrebleu-1.4.13-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (0.29.21)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (0.5.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (2019.12.20)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq==0.9.0) (0.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.9.0) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2273630 sha256=46bcdfa8ade99fca436eb1e535663071912694345461171db7cc0ac446c60ec7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-oovq1q4l/wheels/94/b2/67/6399f5bcb823dc3a8b1e84965aaae15af9ed863fee98a59129\n","Successfully built fairseq\n","Installing collected packages: portalocker, sacrebleu, fairseq\n","Successfully installed fairseq-0.9.0 portalocker-2.0.0 sacrebleu-1.4.13\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"P_V0NEntgMnM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597131571367,"user_tz":-420,"elapsed":80470,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"aead7f84-8d68-4560-c67a-8b07add44ba0"},"source":["# Check version\n","import torch\n","print(torch.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1.6.0+cu101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P5u8JntgeViW","colab_type":"text"},"source":["## Tokenizer"]},{"cell_type":"code","metadata":{"id":"uCTU6Pdmduxo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["105711adf056495182666586fea45cef","a31b05561e1c429c9b9e46ee6ff0d9f7","461683a1fab74a20975eb48a24a67c08","560f0aaeab2a47129260b0c3dd724611","b80dbc185f0742b98a95ceaee8c27462","81972fce9a7543b1a6982b37f3635095","272c966cea0345d18f73bf1ef8066f8d","89666e72b0224f79a1b6a91b801c4e12"]},"executionInfo":{"status":"ok","timestamp":1597131576618,"user_tz":-420,"elapsed":85711,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"2c15ed68-e61d-43ef-a26a-15b793ac9b48"},"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"105711adf056495182666586fea45cef","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9O-3hMyzJkf3","colab_type":"text"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"PdFutqNzI8gu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1597131637718,"user_tz":-420,"elapsed":146802,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"e5bb6449-eaab-4dee-a0da-f75292b92476"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","root_dir = \"/content/drive/My\\ Drive/MasterThesis/CoLab/code_final\"\n","src_dir = \"%s/src\" % root_dir"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nA0sYezlfNVx","colab_type":"text"},"source":["## Translate"]},{"cell_type":"code","metadata":{"id":"2H5grvpAfQ45","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cd40778eabb64c368f1a501267b11e32","719ffb0474d043ceba33af317f6494fd","629ea809b4f1440184c113905e01a1bc","c70f014d37a6457e84343c998032caa3","a5d21435a9334d0cb34cd8a644066590","7420e76e086047be838614cc9704200b","026152914048486ba71246516fb57a21","05481e14183f433dbc0c6af660f2eeec","b781a434a8d440d2a50b5ae2aef0ec8c","0a3fc4dbc1b542ec969c845ffb665eef","5cc0e740766845c29c4a511d5731dab3","e22254df7aa44477a18499019313b1e0","3a633af6a69a4e88a47189fb880b2b3b","27d636bc27174495921a5c714ef2c91d","83e9b2db975b4aaa8a601644aa8b30fe","a638fdf441dd426f90a219963a057018"]},"executionInfo":{"status":"ok","timestamp":1597131742444,"user_tz":-420,"elapsed":251517,"user":{"displayName":"Bằng Nguyễn Minh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggttuw0D2GsQoiDubdDj6OoVN85uU3ReDvQ3v0j=s64","userId":"02689767615379107046"}},"outputId":"cb73d547-953d-4958-c071-961aa919b59e"},"source":["import sys\n","sys.path.insert(0, '/content/drive/My Drive/MasterThesis/CoLab/code_final')\n","import src\n","\n","model = src.TransformerWithBertModel.from_pretrained(\n","    \"/content/drive/My Drive/MasterThesis/CoLab/code_final/model_stage2\",\n","    checkpoint_file='checkpoint_best.pt',\n","    data_name_or_path=\"/content/drive/My Drive/MasterThesis/CoLab/code_final/data\",\n","    bert_model=\"bert-base-multilingual-cased\",\n","    )\n","model.eval() # disable dropout"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd40778eabb64c368f1a501267b11e32","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b781a434a8d440d2a50b5ae2aef0ec8c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["GeneratorHubInterface(\n","  (models): ModuleList(\n","    (0): TransformerWithBertModel(\n","      (encoder): TransformerWithBertEncoder(\n","        (bert_model): BertModel(\n","          (embeddings): BertEmbeddings(\n","            (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","            (position_embeddings): Embedding(512, 768)\n","            (token_type_embeddings): Embedding(2, 768)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (encoder): BertEncoder(\n","            (layer): ModuleList(\n","              (0): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (1): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (2): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (3): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (4): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (5): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (6): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (7): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (8): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (9): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (10): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (11): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","          (pooler): BertPooler(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (activation): Tanh()\n","          )\n","        )\n","      )\n","      (decoder): TransformerDecoder(\n","        (dropout_module): FairseqDropout()\n","        (embed_tokens): Embedding(16184, 768, padding_idx=1)\n","        (embed_positions): SinusoidalPositionalEmbedding()\n","        (layers): ModuleList(\n","          (0): TransformerDecoderLayer(\n","            (dropout_module): FairseqDropout()\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_dropout_module): FairseqDropout()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): TransformerDecoderLayer(\n","            (dropout_module): FairseqDropout()\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_dropout_module): FairseqDropout()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): TransformerDecoderLayer(\n","            (dropout_module): FairseqDropout()\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_dropout_module): FairseqDropout()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): TransformerDecoderLayer(\n","            (dropout_module): FairseqDropout()\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_dropout_module): FairseqDropout()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): TransformerDecoderLayer(\n","            (dropout_module): FairseqDropout()\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_dropout_module): FairseqDropout()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): TransformerDecoderLayer(\n","            (dropout_module): FairseqDropout()\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_dropout_module): FairseqDropout()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (output_projection): Linear(in_features=768, out_features=16184, bias=False)\n","      )\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"0y97nNB9Ojf0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":563},"outputId":"f37e4ae9-327c-40b3-e2fb-47038cfe21a1"},"source":["while True:\n","    print('Nhập câu sai chính tả (q để thoát):')\n","    line = input()\n","    if 'q' == line.rstrip():\n","        break\n","    \n","    tokens = \" \".join(['[CLS]'] + tokenizer.tokenize(line.strip()) + ['[SEP]'])\n","    print(\"Tokenized: %s\" % tokens)\n","\n","    result = model.translate(tokens)\n","    print(\"Output: %s\" % result)\n","\n","    detokenized = ''.join(result).replace(' ', '').replace('▁', ' ')\n","    print(\"Detokenized: %s\" % detokenized)\n","\n","    print('---------------------------------------------------------')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Nhập câu sai chính tả (q để thoát):\n","Học xinh đi học trể.\n","Tokenized: [CLS] Học xin ##h đi học tr ##ể . [SEP]\n","Output: ▁Học ▁sinh ▁đi ▁học ▁trễ .\n","Detokenized:  Học sinh đi học trễ.\n","---------------------------------------------------------\n","Nhập câu sai chính tả (q để thoát):\n","Tôi iêu Diệt Nam.\n","Tokenized: [CLS] T ##ôi i ##êu Di ##ệt Nam . [SEP]\n","Output: ▁Tôi ▁điêu ▁Việt ▁Nam .\n","Detokenized:  Tôi điêu Việt Nam.\n","---------------------------------------------------------\n","Nhập câu sai chính tả (q để thoát):\n","Tôi yêu Diệt Nam.\n","Tokenized: [CLS] T ##ôi yêu Di ##ệt Nam . [SEP]\n","Output: ▁Tôi ▁yêu ▁Việt ▁Nam .\n","Detokenized:  Tôi yêu Việt Nam.\n","---------------------------------------------------------\n","Nhập câu sai chính tả (q để thoát):\n","Tôi iêu Việt Nam.\n","Tokenized: [CLS] T ##ôi i ##êu Việt Nam . [SEP]\n","Output: ▁Tôi ▁điêu ▁Việt ▁Nam .\n","Detokenized:  Tôi điêu Việt Nam.\n","---------------------------------------------------------\n","Nhập câu sai chính tả (q để thoát):\n","Tôi yêu iệt Nam.\n","Tokenized: [CLS] T ##ôi yêu i ##ệt Nam . [SEP]\n","Output: ▁Tôi ▁yêu ▁duyệt ▁Nam .\n","Detokenized:  Tôi yêu duyệt Nam.\n","---------------------------------------------------------\n","Nhập câu sai chính tả (q để thoát):\n","q\n"],"name":"stdout"}]}]}